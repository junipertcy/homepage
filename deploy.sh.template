#!/usr/bin/env bash

set -euo pipefail
IFS=$'\n\t'
temp_dir=""

# Constants
readonly DISTID=""
readonly BUCKET_NAME=""
readonly BUILD_DIR="./dist/browser"
readonly LOG_FILE="/tmp/s3_sync_$(date +%Y%m%d_%H%M%S).log"
readonly REQUIRED_COMMANDS=("ng" "aws" "md5sum" "parallel" "file")

# Function to display usage
usage() {
    cat <<EOF
Usage: ${0##*/} [options]
Uploads the Angular site to AWS S3.

Options:
  -h, --help            Show this message and exit
  -d, --delete-first    Remove specific contents in target bucket before syncing
  -s, --sync            Sync the local directory to the S3 bucket
  -v, --verbose         Enable verbose logging
EOF
}

log() {
    local level=$1
    shift
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] [${level}] $*" | tee -a "$LOG_FILE"
}

check_dependencies() {
    local missing_deps=()
    for cmd in "${REQUIRED_COMMANDS[@]}"; do
        if ! command -v "$cmd" &>/dev/null; then
            missing_deps+=("$cmd")
        fi
    done

    if [[ ${#missing_deps[@]} -gt 0 ]]; then
        log "ERROR" "Missing required commands: ${missing_deps[*]}"
        exit 1
    fi
}

build_angular() {
    log "INFO" "Building Angular project..."
    if ! ng build --configuration production; then
        log "ERROR" "Angular build failed"
        exit 1
    fi
}

generate_file_list() {
    local output_file=$1
    if ! find "$BUILD_DIR" -type f -exec md5sum {} + | \
        sed "s|${BUILD_DIR}/||" | sort > "$output_file"; then
        log "ERROR" "Failed to generate file list"
        exit 1
    fi
}

sync_to_s3() {
    local verbose=$1
    temp_dir=$(mktemp -d)
    local local_files_checksum="${temp_dir}/local_files.txt"
    local s3_files_metadata="${temp_dir}/s3_files.txt"
    
    trap 'rm -rf "$temp_dir"' EXIT

    build_angular
    log "INFO" "Generating local file checksums..."
    generate_file_list "$local_files_checksum"

    log "INFO" "Fetching S3 metadata..."
    if ! aws s3api list-objects-v2 --bucket "$BUCKET_NAME" \
        --query 'Contents[].[Key, ETag]' --output text | \
        sed 's/"//g' | sort > "$s3_files_metadata"; then
        log "ERROR" "Failed to fetch S3 metadata"
        exit 1
    fi

    log "INFO" "Syncing changed files..."
    while IFS= read -r line; do
        local md5 file_path
        md5=$(echo "$line" | awk '{print $1}')
        file_path=$(echo "$line" | awk '{print $2}')
        
        if ! grep -q "$file_path" "$s3_files_metadata" || \
           ! grep -q "$md5" "$s3_files_metadata"; then
            if [[ $verbose == true ]]; then
                log "INFO" "Uploading: $file_path"
            fi
            
            # Detect MIME type
            local mime_type
            mime_type=$(file -b --mime-type "${BUILD_DIR}/${file_path}")
            
            # Set content type based on file extension
            local content_type
            case "${file_path##*.}" in
                js)  content_type="application/javascript" ;;
                css) content_type="text/css" ;;
                *)   content_type="$mime_type" ;;
            esac
            
            if ! aws s3 cp "${BUILD_DIR}/${file_path}" \
                "s3://${BUCKET_NAME}/${file_path}" \
                --acl public-read \
                --content-type "$content_type" \
                --metadata "md5checksum=${md5}" \
                --profile default; then
                log "ERROR" "Failed to upload: $file_path"
            fi
        fi
    done < "$local_files_checksum"

    log "INFO" "Invalidating CloudFront cache..."
    if ! aws cloudfront create-invalidation \
        --distribution-id "$DISTID" \
        --paths "/*" \
        --profile default; then
        log "ERROR" "Failed to invalidate CloudFront cache"
        exit 1
    fi

    log "INFO" "Sync completed successfully"
}


delete_s3_contents() {
    log "INFO" "Removing specified contents from S3 bucket..."
    if ! aws s3 rm "s3://${BUCKET_NAME}" --recursive \
        --exclude "*" \
        --include "*.js" \
        --include "*.css" \
        --include "*.eot" \
        --include "*.woff" \
        --include "*.woff2" \
        --profile default; then
        log "ERROR" "Failed to delete S3 contents"
        exit 1
    fi
}

main() {
    local verbose=false
    local delete=false
    local sync=false

    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help) usage; exit 0 ;;
            -d|--delete-first) delete=true ;;
            -s|--sync) sync=true ;;
            -v|--verbose) verbose=true ;;
            *) usage; exit 1 ;;
        esac
        shift
    done

    check_dependencies

    if [[ $delete == true ]]; then
        delete_s3_contents
    fi

    if [[ $sync == true ]]; then
        sync_to_s3 "$verbose"
    fi

    if [[ $delete == false && $sync == false ]]; then
        usage
        exit 1
    fi
}

main "$@"
